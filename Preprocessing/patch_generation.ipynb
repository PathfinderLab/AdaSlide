{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import openslide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level_of_interest = 0\n",
    "final_patch_size = 512\n",
    "tissue_threshold = 0.7\n",
    "\n",
    "project_list = glob.glob(\"/data/SR-Hist-Foundation/tcga*\")\n",
    "\n",
    "for level_of_interest in [0, 1]:\n",
    "    if level_of_interest == 0:\n",
    "        step_size = final_patch_size\n",
    "        patch_size = final_patch_size\n",
    "        sampling_rate = 0.1\n",
    "    elif level_of_interest == 1:\n",
    "        step_size = final_patch_size * 2\n",
    "        patch_size = final_patch_size * 2\n",
    "        sampling_rate = 0.4\n",
    "    \n",
    "    for project in project_list:\n",
    "        print(project)\n",
    "        project_name = project.split(\"/\")[-1]\n",
    "    \n",
    "        f_path = f\"{project}/*.svs\"\n",
    "        flist = glob.glob(f_path)\n",
    "        \n",
    "        for f in tqdm(flist, leave=False):\n",
    "            # dest = \"/\".join(f.split(\"/\")[:-1]) + \"/\"\n",
    "            dest = \"/data/SR-Hist-Foundation/\"\n",
    "            os.makedirs(dest + \"HR\", exist_ok=True)\n",
    "            os.makedirs(dest + \"LR-x4\", exist_ok=True)\n",
    "            # os.makedirs(dest + \"LR-x8\", exist_ok=True)\n",
    "            \n",
    "            slide = openslide.OpenSlide(f)\n",
    "            dimensions = slide.level_dimensions\n",
    "            \n",
    "            scaling_factor = round(dimensions[0][0] / dimensions[-1][0])\n",
    "            scaled_patch_size = round(patch_size / scaling_factor)\n",
    "            scaled_step = round(step_size / scaling_factor)\n",
    "            \n",
    "            thumbnail = slide.read_region((0, 0), len(dimensions) - 1, dimensions[-1])\n",
    "            thumbnail = np.array(thumbnail).astype(np.uint8)\n",
    "            gray_image = cv2.cvtColor(thumbnail, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "            _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            \n",
    "            for x in range(0, dimensions[-1][1], scaled_step):\n",
    "                for y in range(0, dimensions[-1][0], scaled_step):\n",
    "                    patch = binary_image[x:x+scaled_patch_size, y:y+scaled_patch_size]\n",
    "                    \n",
    "                    tissue_ratio = patch.mean() / 255.\n",
    "                    rng = random.random()\n",
    "                    \n",
    "                    if tissue_ratio >= tissue_threshold and rng < sampling_rate:\n",
    "                        orig_coords = (y * scaling_factor, x * scaling_factor)\n",
    "                        \n",
    "                        ROI = slide.read_region(orig_coords, 0, (patch_size, patch_size))\n",
    "                        if ROI.size[0] != final_patch_size:\n",
    "                            ROI = ROI.resize((final_patch_size, final_patch_size), 3)\n",
    "                            \n",
    "                        # for resolution in [\"HR\", \"LR-x4\", \"LR-x8\"]:\n",
    "                        for resolution in [\"HR\", \"LR-x4\"]:\n",
    "                            if resolution == \"HR\":\n",
    "                                dest_fname = project_name + \"_\" + f.split(\"/\")[-1].split(\".\")[0] + f\"_Level-{level_of_interest}-{orig_coords[0]}-{orig_coords[1]}.png\"\n",
    "                                ROI.save(os.path.join(dest, resolution, dest_fname))\n",
    "                            elif resolution == \"LR-x4\":\n",
    "                                dest_fname = project_name + \"_\" + f.split(\"/\")[-1].split(\".\")[0] + f\"_Level-{level_of_interest}-{orig_coords[0]}-{orig_coords[1]}.png\"\n",
    "                                down_sampled_ROI = ROI.resize((128, 128), 3)\n",
    "                                down_sampled_ROI.save(os.path.join(dest, resolution, dest_fname))\n",
    "                            # elif resolution == \"LR-x8\":\n",
    "                            #     dest_fname = project_name + \"_\" + f.split(\"/\")[-1].split(\".\")[0] + f\"_Level-{level_of_interest}-{orig_coords[0]}-{orig_coords[1]}.png\"\n",
    "                            #     down_sampled_ROI = ROI.resize((32, 32), 3)\n",
    "                            #     up_sampled_ROI = down_sampled_ROI.resize((128, 128), 3)\n",
    "                            #     up_sampled_ROI.save(os.path.join(dest, resolution, dest_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = glob.glob(\"/data/SR-Hist-Foundation/HR/*.png\")\n",
    "result = pd.DataFrame(result, columns=[\"fname\"])\n",
    "\n",
    "result.loc[:, \"project\"] = result.fname.map(lambda x: x.split(\"_\")[1])\n",
    "result.loc[:, \"level\"] = result.fname.map(lambda x: 1 if x.find(\"Level-1\") > 0 else 0)\n",
    "\n",
    "pd.pivot_table(result, index=\"project\", columns=\"level\", aggfunc=\"count\", fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df = [], [], []\n",
    "valid_ratio, test_ratio = 0.05 , 0.005\n",
    "\n",
    "for project_id in pd.unique(result.project):\n",
    "    for level_of_interest in [0, 1]:\n",
    "        sample_df = result.loc[(result.project == project_id) & (result.level == level_of_interest)].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        total_len = len(sample_df)\n",
    "\n",
    "        valid_samples = round(total_len * valid_ratio)\n",
    "        test_samples = round(total_len * test_ratio)\n",
    "        \n",
    "        valid_df.extend(sample_df.loc[:valid_samples, \"fname\"].values.tolist())\n",
    "        test_df.extend(sample_df.loc[valid_samples:valid_samples+test_samples, \"fname\"].values.tolist())\n",
    "        train_df.extend(sample_df.loc[valid_samples+test_samples:, \"fname\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df), len(valid_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import copy\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "def copy_files_to_split_folder(df, split):\n",
    "    assert split in [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "    os.makedirs(f\"/data/SR-Hist-Foundation/HR_{split}\", exist_ok=True)\n",
    "    os.makedirs(f\"/data/SR-Hist-Foundation/LR-x4_{split}\", exist_ok=True)\n",
    "                     \n",
    "    for f in tqdm(df):\n",
    "        try:\n",
    "            HR_source = copy.deepcopy(f)\n",
    "            HR_dest = HR_source.replace(\"HR\", f\"HR_{split}\")\n",
    "\n",
    "            if not os.path.exists(HR_dest):\n",
    "                shutil.copy(HR_source, HR_dest)\n",
    "        except:\n",
    "            print(f\"HR file missing: {HR_source}\")\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            LR_x4_source = copy.deepcopy(f).replace(\"HR\", \"LR-x4\")\n",
    "            LR_x4_dest = LR_x4_source.replace(\"LR-x4\", f\"LR-x4_{split}\")\n",
    "\n",
    "            if not os.path.exists(LR_x4_dest):\n",
    "                shutil.copy(LR_x4_source, LR_x4_dest)\n",
    "        except:\n",
    "            print(f\"LR-x4 file missing: {LR_x4_source}\")\n",
    "            os.remove(HR_dest)\n",
    "\n",
    "copy_files_to_split_folder(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glob.glob(\"/data/SR-Hist-Foundation/HR_test/*.png\")), len(glob.glob(\"/data/SR-Hist-Foundation/LR-x4_test/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_files_to_split_folder(valid_df, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glob.glob(\"/data/SR-Hist-Foundation/HR_valid/*.png\")), len(glob.glob(\"/data/SR-Hist-Foundation/LR-x4_valid/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_files_to_split_folder(train_df, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(glob.glob(\"/data/SR-Hist-Foundation/HR_train/*.png\")), len(glob.glob(\"/data/SR-Hist-Foundation/LR-x4_train/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
